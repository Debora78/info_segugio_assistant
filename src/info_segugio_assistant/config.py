import os

### LLM in Locale
# class Config:
# LLM_MODEL = "llama3.2" # "deepseek-r1:1.5b" # "llama3.2" # "deepseek-r1:1.5b"
# LLM_MODEL_LOW = "llama3.2" # "deepseek-r1:1.5b" # "deepseek-r1:1.5b" # "llama3.2" # "deepseek-r1:1.5b"
# AI_API_URL = "http://localhost:11434/v1"
# AI_API_KEY = "ollama"

### LLM su OpenAI
class Config:
    LLM_MODEL = "gpt-4o" # 
    LLM_MODEL_LOW = "gpt-4o-mini" 
    AI_API_URL = "https://api.openai.com/v1"
    AI_API_KEY = "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"
